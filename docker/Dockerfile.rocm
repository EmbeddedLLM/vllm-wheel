# default base image
ARG REMOTE_VLLM="0"
ARG COMMON_WORKDIR=/app
ARG BASE_IMAGE=rocm/vllm-dev:base

FROM ${BASE_IMAGE} AS base

ARG ARG_PYTORCH_ROCM_ARCH
ENV PYTORCH_ROCM_ARCH=${ARG_PYTORCH_ROCM_ARCH:-${PYTORCH_ROCM_ARCH}}

# Install some basic utilities
RUN apt-get update -q -y && apt-get install -q -y \
    sqlite3 libsqlite3-dev libfmt-dev libmsgpack-dev libsuitesparse-dev \
    apt-transport-https ca-certificates wget curl
# Remove sccache
RUN python3 -m pip install --upgrade pip
RUN apt-get purge -y sccache; python3 -m pip uninstall -y sccache; rm -f "$(which sccache)"

# Install UV
RUN curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR="/usr/local/bin" sh

# This timeout (in seconds) is necessary when installing some dependencies via uv since it's likely to time out
# Reference: https://github.com/astral-sh/uv/pull/1694
ENV UV_HTTP_TIMEOUT=500
ENV UV_INDEX_STRATEGY="unsafe-best-match"
# Use copy mode to avoid hardlink failures with Docker cache mounts
ENV UV_LINK_MODE=copy

ARG COMMON_WORKDIR
WORKDIR ${COMMON_WORKDIR}


# -----------------------
# vLLM fetch stages
FROM base AS fetch_vllm_0
ONBUILD COPY ./ vllm/
FROM base AS fetch_vllm_1
ARG VLLM_REPO="https://github.com/vllm-project/vllm.git"
ARG VLLM_BRANCH="main"
ONBUILD RUN git clone ${VLLM_REPO} \
	    && cd vllm \
	    && git fetch -v --prune --tags origin \
	    && if git show-ref --verify --quiet refs/tags/${VLLM_BRANCH}; then \
	           echo "Checking out tag: ${VLLM_BRANCH}" && \
	           git checkout tags/${VLLM_BRANCH}; \
	       else \
	           echo "Checking out branch: ${VLLM_BRANCH}" && \
	           git fetch -v --prune -- origin ${VLLM_BRANCH} && \
	           git checkout FETCH_HEAD; \
	       fi \
        && if [ ${VLLM_REPO} != "https://github.com/vllm-project/vllm.git" ] ; then \
               git remote add upstream "https://github.com/vllm-project/vllm.git" \
               && git fetch upstream ; fi
FROM fetch_vllm_${REMOTE_VLLM} AS fetch_vllm

# -----------------------
# vLLM build stages
FROM fetch_vllm AS build_vllm

# Pin vLLM dependencies to exact versions of custom ROCm wheels
# This ensures 'pip install vllm' automatically installs correct torch/triton/torchvision/amdsmi
ARG COMMON_WORKDIR
COPY .github/scripts/pin_rocm_dependencies.py /tmp/pin_rocm_dependencies.py
RUN python3 /tmp/pin_rocm_dependencies.py /install ${COMMON_WORKDIR}/vllm/requirements/rocm.txt

# Build vLLM
# Use --find-links to search /install for custom ROCm wheels before PyPI
RUN cd vllm \
    && python3 -m pip install --find-links /install -r requirements/rocm.txt \
    && python3 setup.py clean --all  \
    && python3 setup.py bdist_wheel --dist-dir=dist
FROM build_vllm AS collect_dependencies
ARG COMMON_WORKDIR
# Install pipdeptree for dependency analysis
RUN python3 -m pip install pipdeptree

# Install all built wheels into the environment
RUN cd ${COMMON_WORKDIR}/vllm && python3 -m pip install dist/*.whl

# Export dependency tree
RUN pipdeptree --freeze > ${COMMON_WORKDIR}/all-dependencies.txt

# Copy filtering script and run it
COPY .github/scripts/filter_system_packages.py /tmp/filter_system_packages.py
RUN python3 /tmp/filter_system_packages.py \
    ${COMMON_WORKDIR}/all-dependencies.txt \
    ${COMMON_WORKDIR}/all-dependencies-filtered.txt \
    && mv ${COMMON_WORKDIR}/all-dependencies-filtered.txt ${COMMON_WORKDIR}/all-dependencies.txt

# Remove custom wheels from dependency list (already collected separately)
# This prevents pip from downloading different versions from PyPI
# We check what's actually in /install and filter those packages dynamically
RUN echo "Filtering out custom wheels from dependency list..." && \
    cp ${COMMON_WORKDIR}/all-dependencies.txt ${COMMON_WORKDIR}/all-dependencies-no-custom.txt && \
    for wheel in /install/*.whl; do \
        pkg_name=$(basename "$wheel" | cut -d'-' -f1 | tr '_' '-'); \
        echo "  Excluding $pkg_name from dependencies"; \
        grep -v -E "^${pkg_name}(@| ==|==)" ${COMMON_WORKDIR}/all-dependencies-no-custom.txt > ${COMMON_WORKDIR}/all-dependencies-tmp.txt || true; \
        mv ${COMMON_WORKDIR}/all-dependencies-tmp.txt ${COMMON_WORKDIR}/all-dependencies-no-custom.txt; \
    done && \
    grep -v -E '^vllm(@| ==|==)' ${COMMON_WORKDIR}/all-dependencies-no-custom.txt > ${COMMON_WORKDIR}/all-dependencies-tmp.txt || true && \
    mv ${COMMON_WORKDIR}/all-dependencies-tmp.txt ${COMMON_WORKDIR}/all-dependencies.txt

# Show what we collected
RUN echo "Collected dependencies (after filtering custom wheels):" && cat ${COMMON_WORKDIR}/all-dependencies.txt

# Verify custom ROCm wheels are available at /install
RUN echo "Custom ROCm wheels at /install:" && ls -lh /install/

# Split dependencies into git and regular
RUN grep '^[^@]*@ git+' ${COMMON_WORKDIR}/all-dependencies.txt > ${COMMON_WORKDIR}/git-dependencies.txt || true
RUN grep -v '^[^@]*@ git+' ${COMMON_WORKDIR}/all-dependencies.txt > ${COMMON_WORKDIR}/regular-dependencies.txt || true

# Show what we're processing
RUN echo "Git dependencies to build:" && cat ${COMMON_WORKDIR}/git-dependencies.txt || echo "None"
RUN echo "Regular dependencies to download:" && cat ${COMMON_WORKDIR}/regular-dependencies.txt

# Create dependency wheels directory
RUN mkdir -p ${COMMON_WORKDIR}/dependency-wheels

# Build git dependencies as wheels (if any)
RUN if [ -s ${COMMON_WORKDIR}/git-dependencies.txt ]; then \
      echo "Building git dependencies as wheels..." && \
      pip wheel -r ${COMMON_WORKDIR}/git-dependencies.txt \
        -w ${COMMON_WORKDIR}/dependency-wheels/ \
        --no-deps; \
    else \
      echo "No git dependencies to build"; \
    fi

# Download regular dependencies
# pip will use wheels from /install (referenced in pipdeptree output)
# --find-links ensures pip can find custom wheels when resolving vllm's dependencies
RUN pip download --find-links /install -r ${COMMON_WORKDIR}/regular-dependencies.txt \
    -d ${COMMON_WORKDIR}/dependency-wheels/ \
    --only-binary=:all:

# Show downloaded wheels
RUN echo "Downloaded dependency wheels:" && ls -lh ${COMMON_WORKDIR}/dependency-wheels/

FROM scratch AS export_vllm
ARG COMMON_WORKDIR
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/dist/*.whl /
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/requirements /requirements
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/benchmarks /benchmarks
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/tests /tests
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/examples /examples
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/docker/Dockerfile.rocm /docker/
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm/.buildkite /.buildkite
COPY --from=collect_dependencies ${COMMON_WORKDIR}/dependency-wheels /dependency-wheels
COPY --from=collect_dependencies ${COMMON_WORKDIR}/all-dependencies.txt /all-dependencies.txt

# -----------------------
# Test vLLM image
FROM base AS test

RUN python3 -m pip install --upgrade pip && rm -rf /var/lib/apt/lists/*

# Install vLLM using uv (inherited from base stage)
# Note: No -U flag to avoid upgrading PyTorch ROCm to CUDA version
RUN --mount=type=bind,from=export_vllm,src=/,target=/install \
    --mount=type=cache,target=/root/.cache/uv \
    cd /install \
    && uv pip install --system -r requirements/rocm.txt \
    && uv pip install --system -r requirements/rocm-test.txt \
    && pip uninstall -y vllm \
    && uv pip install --system *.whl

WORKDIR /vllm-workspace
ARG COMMON_WORKDIR
COPY --from=build_vllm ${COMMON_WORKDIR}/vllm /vllm-workspace

# install development dependencies (for testing)
RUN cd /vllm-workspace \
    && rm -rf vllm \
    && python3 -m pip install -e tests/vllm_test_utils \
    && python3 -m pip install pytest-shard

# -----------------------
# Final vLLM image
FROM base AS final

RUN python3 -m pip install --upgrade pip && rm -rf /var/lib/apt/lists/*
# Error related to odd state for numpy 1.20.3 where there is no METADATA etc, but an extra LICENSES_bundled.txt.
# Manually remove it so that later steps of numpy upgrade can continue
RUN case "$(which python3)" in \
        *"/opt/conda/envs/py_3.9"*) \
            rm -rf /opt/conda/envs/py_3.9/lib/python3.9/site-packages/numpy-1.20.3.dist-info/;; \
        *) ;; esac

RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system --upgrade huggingface-hub[cli]

# Install vLLM using uv (inherited from base stage)
# Note: No -U flag to avoid upgrading PyTorch ROCm to CUDA version
RUN --mount=type=bind,from=export_vllm,src=/,target=/install \
    --mount=type=cache,target=/root/.cache/uv \
    cd /install \
    && uv pip install --system -r requirements/rocm.txt \
    && pip uninstall -y vllm \
    && uv pip install --system *.whl

ARG COMMON_WORKDIR

# Copy over the benchmark scripts as well
COPY --from=export_vllm /benchmarks ${COMMON_WORKDIR}/vllm/benchmarks
COPY --from=export_vllm /examples ${COMMON_WORKDIR}/vllm/examples
COPY --from=export_vllm /docker ${COMMON_WORKDIR}/vllm/docker

ENV RAY_EXPERIMENTAL_NOSET_ROCR_VISIBLE_DEVICES=1
ENV RAY_EXPERIMENTAL_NOSET_HIP_VISIBLE_DEVICES=1
ENV TOKENIZERS_PARALLELISM=false

# ENV that can improve safe tensor loading, and end-to-end time
ENV SAFETENSORS_FAST_GPU=1

# Performance environment variable.
ENV HIP_FORCE_DEV_KERNARG=1

CMD ["/bin/bash"]
